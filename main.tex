% 
% Annual Cognitive Science Conference
% Sample LaTeX Paper -- Proceedings Format
% 

% Original : Ashwin Ram (ashwin@cc.gatech.edu)       04/01/1994
% Modified : Johanna Moore (jmoore@cs.pitt.edu)      03/17/1995
% Modified : David Noelle (noelle@ucsd.edu)          03/15/1996
% Modified : Pat Langley (langley@cs.stanford.edu)   01/26/1997
% Latex2e corrections by Ramin Charles Nakisa        01/28/1997 
% Modified : Tina Eliassi-Rad (eliassi@cs.wisc.edu)  01/31/1998
% Modified : Trisha Yannuzzi (trisha@ircs.upenn.edu) 12/28/1999 (in process)
% Modified : Mary Ellen Foster (M.E.Foster@ed.ac.uk) 12/11/2000
% Modified : Ken Forbus                              01/23/2004
% Modified : Eli M. Silk (esilk@pitt.edu)            05/24/2005
% Modified : Niels Taatgen (taatgen@cmu.edu)         10/24/2006
% Modified : David Noelle (dnoelle@ucmerced.edu)     11/19/2014

%% Change "letterpaper" in the following line to "a4paper" if you must.

\documentclass[10pt,letterpaper]{article}

\usepackage{cogsci}
\usepackage{pslatex}
\usepackage[natbibapa]{apacite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{xcolor}  % for \todo
\usepackage{graphicx}
\usepackage{csquotes}
\MakeOuterQuote{"}
\usepackage{booktabs}

\title{Compositional subgoal representations for planning and problem-solving}

\newcommand{\todo}[1]{\textcolor{red}{\textsc{[TODO: #1]}}}
\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\MISSING}{\red{XX}}

\author{TODO}


\begin{document}

\maketitle


\begin{abstract}
When faced with a complex problem, people naturally break it up into several simpler problems. This hierarchical decomposition of an ultimate goal into sub-goals facilitates planning by reducing the number of factors that must be considered at one time. However, it can also lead to suboptimal decision-making, obscuring opportunities to make progress towards multiple subgoals with a single action.
% This potential for suboptimality can be ameliorated by considering multiple subgoals at once, but at the cost of increasing the number of factors that must be considered and thus increasing the computational burden of planning.
Is it possible to take advantage of the hierarchical structures of problems without sacrificing opportunities to kill two birds with one stone?
We propose that people are able to do this by representing and pursuing multiple subgoals at once. We present a formal model of planning with compositional goals, and show that it explains human behavior better than the standard "one-at-a-time" subgoal model as well as non-hierarchical limited-depth search models.
Our results suggest that people are capable of representing and pursuing multiple subgoals at once; however, there are limitations on how many subgoals one can pursue concurrently. We find that these limitations vary by individual and can be modulated by task incentives.
% Furthermore, we find that the degree to which composite goal representation is limited may be an important latent dimension for explaining individual differences in planning ability.
% Finally, we find that the  are sensitive to the cost of suboptimal planning, indicating that people may rationally choose a goal representation that trades off between representational costs and decision quality.

\textbf{Keywords:} 
planning; problem solving; hierarchy; goals
\end{abstract}


\section{Introduction}

It's Tuesday afternoon and you have a list of errands to run before you can return home to watch last night's episode of \textit{The Bachelor}. You need to mail a letter, pick up broccoli for tonight's stir fry, and drop off a book at the library. You are eager to get home to see whether Hannah B. received one of the coveted roses, and thus want to accomplish these tasks as expediently as possible. There are two library locations, four grocery stores, and who knows how many mail boxes in your town; how do you decide which location of each to visit, and in what order? Unfortunately, you have been presented with the generalized traveling salesman problem, which is known to be NP-hard (that is, potentially very difficult to solve). You might simplify the problem by focusing on only one errand at a time, completing it as quickly as possible from wherever the last errand left you. But by ignoring your other tasks when planning how to complete one, you might miss the opportunity to save time by going to the library location that is further from your house, but right next to a grocery store.

% To solve complex problems, it is necessary to break them down into subproblems [cite AI]. People do this []. The standard model of organizing problems into subproblems 

% The ability of people to solve problems such as these has typically been formulated in terms of search \citep{NewellSimon1972}. Under this theory, people construct a "decision tree" that represents possible courses of actions and their outcomes, searching over the tree for the best possible plan. However, these decision trees can quickly become too large to search exhaustively, necessitating approximation strategies \citep{Huys2015}. A particularly valuable strategy for directing search is \textit{subgoaling} \citep{Donnarumma2016}. By focusing on one subgoal at a time, one can ignore irrelevant actions and features of the environment, effectively reducing the size of the decision tree to search over \citep{Dietterich2000}. However, by dividing the space in this way, one will miss opportunities to make progress towards multiple subgoals at once. Of course, people often \textit{do} identify these opportunities, posing a problem for the standard one-at-a-time model of subgoal pursuit.

The ability of people to solve problems such as these has typically been formulated in terms of search over an internal representation of the problem space~\citep{NewellSimon1972}. However, the combinatorial explosion of possible action sequences makes exhaustive search intractable, necessitating approximation strategies~\citep{Huys2015}. One particularly valuable strategy for directing search is \textit{subgoaling}~\citep{Donnarumma2016}. By focusing on a single subgoal at a time, one can ignore irrelevant actions and features of the environment, effectively reducing the dimensionality of the problem space~\citep{Dietterich2000}. However, this reduction comes at a cost. Standard models of goal-setting and hierarchical planning assume that subgoals are \textit{context-free} in the sense that they are pursued independently, without consideration of the ultimate goal or future subgoals. As a result, opportunities to make progress towards multiple subgoals at once will be missed. Nevertheless, people often \textit{do} identify these opportunities. This poses a problem for the standard one-at-a-time model of subgoal pursuit.

% How can we reconcile the strong evidence for hierarchical structure in human behavior \citep{Cooper2006} with our 

How might people enjoy the benefits of hierarchical decomposition without being shackled by the artificial boundaries it imposes on a problem?
One possibility is that, contrary to the standard model, people are not limited to pursuing one goal at a time. That is, perhaps they choose a \textit{subset} of goals, and construct a plan that is optimal with respect to that subset.
They might ask themselves, for example, "what is the fastest way to get to both a grocery store and a library?", leaving future goals such as dropping off a letter for future consideration.
We formalize this theory in a hierarchical planning framework.
At the abstract level, the agent dynamically constructs composite goals (or \textit{multigoals}) from a set of primitive goals. Then, at the concrete level, the agent searches for a plan that achieves the composite goal, disregarding any other potential future goals. 

We begin the paper with an overview of previous attempts to capture the way that people use subgoals to hierarchically decompose problems, emphasizing how these approaches fail to capture the flexibility that people have to consider multiple goals at once. Next, we formalize the multigoal model as an extension of a hierarchical planning algorithm. To test the multigoal model, we identify a classic task from the problem solving literature that can provide a behavioral signature of the subgoal representations underlying our participant's choices (if such representations exist). Using a Bayesian modeling framework, we can dissociate constraints on the number of subgoals they can pursue at once from goal-agnostic constraints on the depth of search. Finally, we use formal model comparison to demonstrate that the multigoal model explains participant behavior better than both goal-free and single-goal models.

% To test the multigoal model, we first identify a classic task from the problem solving literature that can provide a behavioral signature of the subgoal representations underlying our participant's choices (if such representations exist). Using a Bayesian modeling framework, we can dissociate constraints on the number of subgoals they can pursue at once from goal-agnostic constraints on the depth of search. Finally, we use formal model comparison to demonstrate that the multigoal model explains participant behavior better than both goal-free and single-goal models.

% We begin the paper by discussing relevant theoretical approaches to planning and problem solving. We then present a formal model of planning with composite \textit{multigoals}. Next, we present an experiment designed to dissociate the predictions of the multigoal model from those of standard depth-limited search and hierarchical planning models. We discuss the application of the general model to the specific problem, and present model fitting results. We conclude with a discussion of next steps.


\section{Background}
Much previous work in psychology has studied the strategies people use to make planning and problem solving tractable. In particular, we focus on two non-exclusive classes of strategies that have been studied: \textit{tree search} and \textit{hierarchical decomposition}. Tree search strategies take inspiration from algorithms based on search through a decision tree, in which possible plans are simulated forward and evaluated~\citep{NewellSimon1972}. For example, rather than consider plans that are arbitrarily long, people can engage in \textit{depth-limited search} that focuses resources on plans that can be taken within a certain time horizon~\citep{MacGregor2001,Keramati2016,Krusche2018}. Alternatively, they may rely on heuristics to guide search~\cite[chap. 5]{Anderson1990} or use local signals of progress to avoid less promising plans without explicitly considering them~\citep{Huys2012}.

However, approaches such as depth-limited search and heuristics are, in a sense, limited by their locality---what if the goal is many timesteps away, or even just out of reach? What if the heuristic cues are uninformative or simply do not exist? This, in part, motivates complementary approaches based on \textit{hierarchical decomposition}, in which a problem is holistically broken into sub-problems, each of which are then solved in the right order~\citep{sacerdoti1974planning, botvinick2012hierarchical}. Such an approach can make decision-making easier by reducing the resources needed to solve a given sub-problem at a particular time~\citep{VanDijk2011, Maisto2015}. But this raises yet another problem: What is a good way to break down a task? And what if the particular decomposition could be improved?

The Sussman anomaly exemplifies what happens when a decomposition is too  brittle (Figure~\ref{fig:suss}, \citealp{Sussman1975}). In the Sussman anomaly, an agent plans with respect to a single subgoal at a time (e.g., put block A on top of block B) without considering the larger context of that subgoal with respect to other subgoals. That is, subgoals are completely \textit{context-free}. This can lead to inefficiencies (e.g., having to move A and B again in order to get B on top of C) that could have been avoided. More generally, some efficiencies in problems can only reliably be achieved by planning with respect to multiple subgoals since plans based on individual subgoals may be myopic, greedily optimizing for the subgoal at hand. For instance, Figure \ref{fig:fourblock} demonstrates a case where considering a single subgoal might result in a suboptimal solution that is avoided when considering multiple subgoals. 
% More generally, agents planning with respect to different numbers of subgoals take actions with different probabilities in various states, which forms the basis of our modeling framework.

% \subsection{Search and its limitations}

% Many of the hallmarks of higher level human cognition, such as problem solving \citep{NewellSimon1972}, strategic reasoning \citep{Holding1985}, and planning \citep{Simon2011} have been modeled as search over a decision tree. In each case, the problem at hand is represented as a tree, with nodes representing possible future states and branches representing decisions one could make in those states.

% In complex domains, exhaustive search is computationally intractable; thus search must be curtailed in some way. When extensive experience is available, people may avoid search by relying on model-free reinforcement learning \citep{Keramati2011,Kool2017} or cached action sequences \citep{Huys2015}. When rewards are dense, they may use these local signals of progress to avoid less promising branches of a decision tree \citep{Huys2012}. However, many of the problems people encounter in their daily lives lack such structure.

% When full search is infeasible and progress cues are limited or unreliable, people may have to impose arbitrary constraints on their search. The simplest such constraint is to put a limit on how far into the future you look. So-called \textit{depth-limited search} has been incorporated into several models of human search \citep{MacGregor2001,Keramati2016,Krusche2018}.
% Under this strategy, the searcher considers all possible action sequences of some length $d$, and chooses the one that gives the best intermediate outcome. How the intermediate outcome is defined depends on the problem domain, and can have substantial effects on the choices that are ultimately made. For planning in reward-maximization problems, this outcome is typically the sum of rewards one receives along this path (perhaps augmented with a learned value of the final state; \citealp{Keramati2016}). In problem solving settings, there are typically no intermediate rewards, and a heuristic estimate of distance to the goal state is used to evaluate partial plans \cite[chap. 5]{Anderson1990}. A good heuristic can reduce or even eliminate the need to look far into the future, resulting in a "hill climbing" strategy. But for more challenging problems, people may require more complex strategies to guide their search.

% \subsection{Subgoals and hierarchical planning}
% Many of the complex problems that people face in their daily lives can naturally be decomposed into smaller problems. People can take advantage of this structure by setting \textit{subgoals}, intermediate goals (e.g. pick up broccoli) that each contribute to achieving a larger goal (cook dinner) which itself may be part of an even broader goal (avoid starvation). This approach can ultimately make decision-making easier, reducing working memory requirements \citep{VanDijk2011} and/or computational complexity \citep{Maisto2015}. However, it also creates a new problem: How should one choose subgoals that will both accomplish the ultimate goal, and also be relatively easy to solve individually? \textit{Hierarchical planning} is one way to answer this question. 

% In hierarchical planning, search occurs at different levels of abstraction~\citep{sacerdoti1974planning}. At the top level, one plans over potential sequences of subgoals to pursue in order to accomplish the ultimate goal. Each subgoal then becomes its own planning problem in which one plans over sequences of actions (or perhaps simpler subgoals) to accomplish that subgoal. Hierarchical planning has been studied as a way in which humans learn to solve complex tasks~\citep{botvinick2012hierarchical} and also as a method for scaling up automated planning systems~\citep{kaelbling2010hierarchical}. Research on hierarchical planning has traditionally focused on learning or planning given a particular decomposition~\citep{sacerdoti1974planning, parr1998reinforcement}, and more recent approaches have examined learning hierarchical planning representations through interaction with an environment or from another agent's demonstrations~\citep{bacon2017option, cobo2014abstraction}. From a functional perspective, hierarchical task decompositions enable adaptive systems to trade off behavioral optimality with computational resources. A key question is then what properties of a decomposition facilitate this tradeoff.

% Algorithms for learning policies in hierarchically structured tasks assume that subpolicies are insensitive to the context they're executed in. The assumption that subpolicies are context-free is termed \textit{recursive optimality} \citep{Dietterich2000} and ensures that these subpolicies can flexibly be applied in many contexts. The Sussman anomaly exemplifies a case where acting optimally with respect to individual subgoals renders a problem impossible to complete. This issue can be avoided by changing the structure of subgoals or planning with respect to multiple subgoals. More generally, some efficiencies in problems can only reliably be achieved by planning with respect to multiple subgoals as plans based on individual subgoals may be myopic, greedily optimizing for the subgoal at hand. For instance, Figure 1 demonstrates a case where considering a single subgoal might result in a suboptimal solution that is avoided when considering multiple subgoals. More generally, agents planning with respect to different numbers of subgoals take actions with different probabilities in various states, which forms the basis of our modeling framework.

% \todo{This might be too much detail for the background}
% Our work here can be understood as analyzing \textit{subgoal resolution} as a factor in the construction of hierarchical plans in humans. At a particular moment in time, a person will have a subgoal they want to complete. Compare the subgoal ``mail a letter'' with the subgoal ``mail a letter AND go to the grocery''. The second subgoal has higher \textit{resolution} than the first in that it is more specific and picks out a strictly smaller set of states as acceptable for completion. This factor is a key element for any hierarchical planning scheme. For example, in formalisms such as the options framework~\citep{sutton1999between}, macro-actions (i.e., options) are defined in part by the set of states in which one exits an option. Our approach can be understood then as considering the complexity of the predicates defining a termination condition when people hierarchically decompose a task.


\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.5\textwidth]{example-suss}
    \caption{Sussman's anomaly. In this block stacking problem, the aim is to stack the blocks in alphabetical order by satisfying two subgoals: stack B on C and stack A on B. Planning towards one subgoal at a time results in taking actions that will need to be reversed. Only by jointly considering the subgoals can the problem be efficiently solved.}
    \label{fig:suss}
\end{figure}

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{example-4-block}
    \caption{
    Planning with multigoals of different size $k$ can lead to different action sequences. In this example, planning with $k=2$ ensures that A is moved first which avoids extraneous actions at future states. Green blocks represent subgoals that have been satisfied and blue blocks represent the subgoals in the current multigoal, used to plan the next action.
    
    %Planning to stack C on D might result in either of the two depicted plans, where A or B is first removed. Removing A first (the lower plan) winds up being more efficient, taking 1 step fewer to achieve the goal state. When planning with respect to two subgoals (stack C on D and stack B on C), an agent will always choose to remove A first (like in the lower plan) since they are optimizing for the eventual placement of B. Blocks are green when their corresponding subgoal has been satisfied.
    }
    \label{fig:fourblock}
\end{figure*}



\section{Planning with multigoals}
\newcommand{\multigoal}{\mathcal{G}}

Multigoals extend a standard goal-based hierarchical planning algorithm by allowing for new subgoals to be constructed on the fly by composing existing, primitive subgoals. Formally, we define a multigoal,  $\multigoal$, as a set of primitive subgoals. Following the options framework \citep{sutton1999between}, a subgoal $g$ is defined by a function 
$\beta_g: \mathcal{S} \rightarrow \{0, 1\}$
that indicates whether a state satisfies the given subgoal. A multigoal is satisfied by a state that satisfies all of its component subgoals; thus, a multigoal's satisfaction function is defined
$\beta_{\multigoal}(s) = \prod_{g \in \multigoal} \beta_g(s)$. Although multigoals can be integrated into arbitrarily deep hierarchical planning models for stochastic environments, we focus on the simplest case of a two-level hierarchy and deterministic environments. At the abstract level the agent chooses a multigoal based on the current state and ultimate goal. At the concrete level, the agent attempts to find a sequence of actions that satisfies the current multigoal.

A full abstract-level planning model would both identify possible subgoals and also choose which ones to pursue at each step. However, to simplify the problem, we assume that the goals and their ordering are given. That is, the agent receives an ordered set of subgoals $\{ g_1, g_2, \dots g_n  \}$ such that completing all $n$ subgoals in order amounts to solving the ultimate goal. The abstract-level phase of planning is thus reduced to selecting a number of subgoals to pursue; we call this number $k$. Given a selection of $k$ and the multigoal in a given state, $\multigoal(s; k)$ is simply the set of the next $k$ incomplete subgoals. For example, if $g_1$ has been completed ($\beta_{g_1}(s) = 1)$ and $k=2$, we would have $\multigoal(s; k=2) = \{ g_2, g_3 \}$. Admittedly, this simplifying assumption eliminates a considerable amount of interesting complexity. However, it allows us to look for experimental evidence for multigoals without tackling the full problem of multigoal selection. Relaxing this assumption is an important direction for future work.

% \begin{equation}
%   \multigoal(s; k) = \{g_i \dots g_{i+k-1} \} \text{ s.t. } 
%     \beta_{g_{i-1}}(s) = 1 \wedge \beta_{g_i}(s) = 0
% \end{equation}

Given a multigoal $\multigoal$, concrete-level planning uses tree search to find a lowest-cost path $\pi$ that satisfy all subgoals in $\multigoal$. This search process may be depth-limited. If no path of length $d$ or less can be found that satisfies all the subgoals, the model chooses a path that satisfies the largest possible number of subgoals. Thus, the action sequence is chosen by
%
\begin{equation}\label{eq:concrete}
  \arg\max_\pi 
    \sum_{g \in \multigoal} \beta_g(s_\pi) - \lambda |\pi |
    \; \text{ s.t.  } |\pi| \leq d,
\end{equation}
%
where $s_\pi$ is the final state on the path defined by the action sequence $\pi$ and $\lambda$ is a very small positive constant, with the effect that $\pi$ is chosen to maximize the first term (number of subgoals completed), using the second term (path length) as a tie-breaker.

There are several special cases of the model worth highlighting. When $k = 1$, we recover a standard hierarchical planning algorithm in which only one subgoal is pursued at a time. When $k = \infty$, we recover a standard depth-limited search model with a heuristic cost function defined by the number of incomplete subgoals. When $d = \infty$, the model optimally achieves each multigoal, but may still perform suboptimally because future subgoals are not considered. And when $d = k = \infty$, the model always makes optimal choices.


\section{Experiment 1: Measuring human multigoaling}

To test the predictions of the multigoal model, we conducted a Tower of London (ToL) experiment~\citep{Shallice1982} where an initial configuration of stacked items must be rearranged to match a goal configuration by moving one item at a time. The classic ToL task is based on the Tower of Hanoi problem, removing the constraints imposed by different-sized disks, but adding a limit to how many disks can be on each peg. Our variant of ToL uses blocks instead of disks and removes the restrictions on stack height. We additionally mark the blocks with letters and use a single standard goal position to reduce working memory requirements. This results in an unambiguous subgoal ordering~\citep{Kaller2011}: One must put blocks in their place in reverse alphabetical order.
% Thus, the model's simplifying assumption that the order of subgoals is given is innocuous in this specific setting. 

% With these modifications to the rules, our experimental task resembles Blocks World, a domain used to investigate problem solving in artificial intelligence research \todo{XXX connect to Sussman}.

% \todo{Integrate the text below with the text above, probably cutting some extraneous material}

% Prior work \citep{Simon1975} has established various strategies people might use when solving ToH puzzles, and other studies have even taught specific strategies to people to examine the relationship between the underlying cognitive mechanisms implicated by these strategies and measures like response time \citep{Anderson2001} and fMRI signal \citep{Anderson2005}.


\subsection{Methods}
\subsubsection{Stimuli and procedure}

In each trial, participants are presented with two configurations of stacked blocks marked with letters of the alphabet and asked to rearrange the blocks in one stack to match the blocks in the goal configuration (Fig. \ref{fig:ui}). Only the top block of a stack can be moved, and the board is limited to contain at most three spaces (columns) for stacks. In all trials, the goal configuration is a single stack arranged in alphabetical order in the middle column.

Participants completed three tutorial trials of increasing difficulty (a 3-block trial, a 4-block trial, and a 5-block trial) and then completed sixteen 6-block trials. Only the 6-block trials are analyzed below. Problems were selected to maximize the difference in likelihood of the fixed $k$ multigoal model (Equation~\ref{eq:likelihood-fixed}) and the depth-limited model on data simulated from multigoal agents with $k \in \{ 1,2,3,4 \}$. That is, the problems were optimized to distinguish the behavioral signature of multigoals from that of constraints on search depth.

\begin{figure}[t!]
    \centering
    \includegraphics[width=6cm]{example-block-world.png}
    \caption{Experimental interface. On the left is the initial state which must be rearranged to match the goal state at right.}
    \label{fig:ui}
\end{figure}

\subsubsection{Participants}
We recruited 41 participants from Amazon Mechanical Turk. Each participant received \$2 for completing the task, which took an average of 9 minutes.

\subsection{Model}
 
According to the proposed multigoal model, people can select multiple subgoals to pursue concurrently, attempting to create a plan that satisfies all $k$ subgoals in the fewest steps. We define a subgoal in the experimental task as putting a block in its correct final position. Thus, we have an ordered set of subgoals $\{ g_F, g_E, g_D, g_C, g_B, g_A \}$ such that completing them in order necessarily solves the full problem. This satisfies the simplifying assumption required by the model.
%, and \red{it is not unreasonable to assume that such a subgoal structure is apparent to the experimental participants.}


\newcommand{\A}{\mathcal{A}}
\newcommand{\U}{\mathcal{U}}

We now derive a likelihood to use for model fitting and comparison. Given a state and a value for $k$, the model selects a multigoal $\multigoal(s; k)$ which is the set of the next $k$ uncompleted subgoals. Then, given this multigoal and a value for $d$, we find a set of optimal paths given by Equation~\ref{eq:concrete}. In the case of ties, it is not obvious how to determine which path should be chosen because the probability of finding a given path depends on the specific search algorithm one uses, a detail we remain agnostic about. Thus, the model simply divides probability uniformly among the set of unique first actions in any of the identified paths. Call this set $\A^*(s; k, d)$, which is a subset of all allowable actions $\A(s)$. We can now define the likelihood of taking a single action in a given state as
%
\begin{equation}\label{eq:likelihood-fixed}
  \Pr(a \mid s; k, d, \epsilon) = 
  (1 - \epsilon) \cdot \U(a \mid \A^*(s; k, d)) + 
  \epsilon \cdot \U(a \mid \A(s)),
\end{equation}
%
where $\U$ is the Uniform distribution. Note that by defining the likelihood for each action independently, we implicitly assume that participants re-plan at every step. Relaxing this assumption complicates model-fitting considerably, but it is an important direction for future work.

To test the multigoal model, in particular to evaluate whether people show evidence of pursuing more than one goal at a time, we employ formal model comparison. The comparisons of greatest interest are special cases of the full model. A standard depth-limited search model sets $k=\infty$ and has $d$ (the search depth) as a free parameter. A standard hierarchical planning or subgoaling model sets $k=1$, allowing for only one subgoal to be pursued at a time, and also has $d$ as a free parameter. In the full model, both $k$ and $d$ are free.

We consider two hypotheses for how $k$ and $d$ are chosen when they are free parameters. The first hypothesis is that the parameter is fixed for each individual. For example, one person might always consider two subgoals at a time ($k=2$)  and search fourteen steps into the future ($d=14$). The second hypothesis is that $k$ and $d$ vary from decision to decision, but follow some distribution that is particular to each individual. For example, one person might typically consider one subgoal at a time but occasionally pursue two (or rarely, three) subgoals at a time. We consider two possible distributions for both $k$ and $d$: the Geometric distribution, which has a strong positive skew, and the Poisson distribution, which can distribute mass more evenly around a mean. Because these distributions both have a single parameter, they do not increase the number of parameters in the full model. To compute the likelihood, we integrate out the latent $k$ and $d$ parameters. Thus, for the models that put distributions over $k$ and/or $d$ with parameters $\theta_k$ and $\theta_d$ we have
%
% \begin{equation}\label{likelihood-dist}
% \begin{aligned}
%   \Pr(a \mid s; \theta_k, \theta_d, \epsilon) = 
%     \sum_{d=1}^{d^*}\sum_{k=1}^{k^*} 
%       \Pr(a \mid s; k, d, \epsilon) \Pr(k ; \theta_k) \Pr(d ; \theta_d) \\
%       + \Pr(a | s; k=\intfy, d=\infty, \epsilon)
%         \Pr(K > k^*; \theta_k) \Pr(D > d^*; \theta_d)
% .
% \end{aligned}
% \end{equation}
%

\begin{equation}\label{eq:likelihood-dist}
  \Pr(a \mid s; \theta_k, \theta_d, \epsilon) = 
    \sum_{d=1}^{\infty} \sum_{k=1}^{\infty}
      \Pr(a \mid s; k, d, \epsilon) \Pr(k ; \theta_k) \Pr(d ; \theta_d) \\
.
\end{equation}
Despite the infinite summation, we can compute this value exactly because we need only enumerate each parameter up to the value at which it results in optimal decision making, $\theta^*$. All greater values give the same prediction, thus we can treat them as a single bin with probability $\Pr(\theta > \theta^*) \Pr(a \mid s; \theta^*)$.


We fit all models by maxmimum likelihood estimation. For discrete parameters we used grid search, considering all possible values of $k \in \{ 1 \dots 6 \}$ and values of $d \in \{1 \dots 15 \}$. We chose 15 as this was the farthest a participant ever was from a goal state. For continuous parameters, we used L-BFGS.


\subsection{Results}

\begin{figure}[t!]
  \centering
  \includegraphics[scale=0.55]{model-fits}
  \caption{Relative model performance. Each point represents one model fit to the data of one participant. For ease of comparison, we normalize the AIC values for each participant by the AIC of their best fitting model. The same additive transformation is applied to the AIC values for each model, and thus the mean differences between models are not affected.} 
  \label{fig:model-fits}
\end{figure}

\begin{table}[t!]
  \centering
  \begin{tabular}{lrrrr}
  \toprule
  Model         & \# Parameters & AIC   & LL    & \# Best fit \\
  \midrule
  Geometric $k$/$d$ & 3 & \textbf{10533} & -5143 & 12 \\
  Poisson $k$/$d$ & 3 & 10541 & -5147 & 10 \\
  Poisson $k$ & 2 & 11234 & -5535 & 2 \\
  Geometric $k$ & 2 & 11250 & -5543 & 2 \\
  Fixed $k$/$d$ & 3 & 11518 & -5636 & 0 \\
  Fixed $k$ & 2 & 11705 & -5770 & 0 \\
  Poisson $d$ & 2 & 12364 & -6100 & 7 \\
  $k$=1 & 1 & 12482 & -6200 & 6 \\
  Geometric $d$ & 2 & 13062 & -6449 & 2 \\
  Fixed $d$ & 2 & 13348 & -6592 & 0 \\
  \bottomrule
  \end{tabular}
  \caption{Model comparison: Columns are number of parameters per participant, Akaike information criterion, log likelihood, and the number of participants best fit by the model.}
  \label{tab:model-fits}
\end{table}

We fit the parameters of each model separately for each participant. Results are summarized in Figure~\ref{fig:model-fits} and Table~\ref{tab:model-fits}. We highlight three primary results below.

First, all models that include multigoals (the first six rows in the table) explain the data significantly better than the $k=1$ model. This suggests that people are not limited to pursuing one subgoal at a time. That being said, for some participants, the best fitting $p_k$ parameter in the Geometric $k/d$ model was close to one, resulting in single subgoal planning in most cases (See Fig. \ref{fig:p_k}). In particular $p_k$ was greater than 0.95 for 17 out of 41 participants, suggesting that these participants considered more than one subgoal at most 5\% of the time.

% Of particular note is that many participants are best explained by a $k=1$ model or Geometric distribution with large $p$ (which acts like the $k=1$ model with probability $p$). The case of $k=1$ amounts to simple hierarchical planning, where search finds optimal paths towards the next incomplete subgoal. It's particularly interesting that the $k=1$ is a comparable fit to the best depth model in 27 out of 41 participants, suggesting that in at least this task even very simple goal representations are a strong constraint on search that can explain action comparably to well-established models of search.

Second, all models with free $k$ parameters performed better than the models with free $d$ parameters. This suggests that limits on composite subgoal representations provide a better explanation for participants' behavior than limits on the depth of search. However, models that include both kinds of limits perform best. This suggests that human problem solving may be jointly constrained by subgoal representations and search depth, and that these two constraints each provide unique contributions to explaining behavior.

Third, models with distributions over model parameters $k$ and $d$ always performed better than the corresponding models with fixed parameters. This suggests that people consider different numbers of subgoals and search to different depths at different points. This effect could be due to changing problem. The configuration of blocks at any moment may determine, for example, the number of subgoals a person is capable of considering. An alternative (although not mutually exclusive) explanation is that our participants adaptively adjusted the complexity of their multigoals, choosing how much effort to put into the problem based on an estimate of how much doing so will improve their performance \citep{Shenhav2017,lieder2017strategy}.

% Under this explanation, we would predict that people will use more complex multigoals when finding an efficient solution is more important. We set out to test this prediction in a second experiment.

% Models with distributions over $k$ were better fits than models with distributions over $d$ in 28 out of 41 participants, suggesting that goal-based planning may better explain participant actions than depth limits in this task.


% The joint model with Geometric distributions over $k$ and $d$ is the best fit for 22 out of 41 participants and best overall fit, suggesting that jointly considering these limits is essential to explaining action in our task.

% modulating > modulate. I think it's better to make a strong statement. I don't think it's important to match the "-ing" construction in the Experiment 1 title. -Fred
% \section{Experiment 2: Incentives modulate multigoal complexity}
% In Experiment 1, participants were incentivized to find short solutions only to the extent that it allowed them to complete the experiment more quickly. Because executing moves is very fast in this task, the benefit of considering multiple goals (and thus finding shorter solutions) was not great, perhaps outweighed by the cognitive effort associated with more complex multigoals. To explore whether people may adapt the size of their multigoals in response to increasing pressure to solve problems efficiently, we conducted a second experiment in which participants were incentivized to take as few moves as possible on each problem.

% \section{Methods}
% \subsubsection{Stimuli and procedure}
% The primary modification from Experiment 1 was the introduction of a points system. Participants began half of trials with some number of points, which was decremented each time they moved a block. The initial points for each problem was set to the 95\% quantile of the number moves taken on that problem in Experiment 1. After solving each problem, the leftover points were added to a running total. At the end of the experiment, participants were given bonus payments equal to one cent per point. The other half of trials had no points and no bonus. To maximize statistical power, we duplicated each problem from Experiment 1, presenting it once as a problem with a bonus and again as a problem with no bonus. To reduce the probability of participants noticing the duplicates, we swapped the left and right columns of the initial state, a manipulation that changes the visual appearance without altering the abstract structure of the problem. This procedure revealed that two of the problems selected for Experiment 1 were already mirrored duplicates of another problem. We replaced these two problems with new problems, and conservatively set the number of initial points to the largest of the other problems.

% \subsubsection{Participants}
% We recruited 47 participants from Amazon Mechanical Turk. Each participant received \$2.75 for completing the task, plus a performance-dependent bonus (mean: \$0.77). The task took an average of 18 minutes.

% \subsection{Results}

\begin{figure}[ht]
    \centering
    \includegraphics[scale=0.55]{geom-k-p}
    \caption{Distribution of $\Pr(k > 1)$ (equivalently, parameter $1-p_k$ for Geometric $k$/$d$ model) suggests the use of multigoals.}
    \label{fig:p_k}
\end{figure}

% Participants in Experiment 2 were able to solve the problems in fewer moves on average compared to participants in Experiment 1 ($p < 1e-5$), although comparing high-stakes trials in Experiment 2 did not result in a meaningful difference compared to low-stakes trials ($p > 0.5$). Additionally, repeated trials in Experiment 2 were not completed in fewer moves on average ($p > 0.2$), indicating that subjects performed similarly on repeated trials \todo{do paired test}.

% Participants in Experiment 2 exhibited lower termination probability $p_k$ for their fit Geometric distributions over $k$ compared to participants in Experiment 1 ($p < 1e-3$, see Figure \ref{fig:p_k} \todo{Compare to model for both incentive conditions}). This directly corresponds to a higher likelihood of acting consistently with $k > 1$, as $1-p_k$ is the likelihood of acting like $k > 1$, suggesting increased use of multigoals. However, high-stakes trials in Experiment 2 did not result in different termination probability $p$ compared to low-stakes trials ($p > 0.95$).

% \todo{\textbf{\Large TOM}: However, the expected value of $k$ for the Geometric distribution is not significantly different. In addition, $p$ is not normally distributed, so using a linear model to make the above comparison isn't appropriate. Please advise.}

% Taken together, these results suggest that the addition of an incentive in Experiment 2 led to fewer moves on average due to increased use of multigoals, but a higher incentive in Experiment 2 did not change the strategies employed by participants.

\section{Discussion}
  
To solve complex problems, people have to break them down into smaller problems. The importance of subgoals has been long recognized, and they play a critical role in the most successful models of human problem solving \citep{anderson2013architecture,NewellSimon1972,laird1987soar}. However, these models are limited by the assumption that only one subgoal can be pursued at a time. To address this limitation, we have extended the classic subgoaling model with the notion of a multigoal, a subset of subgoals that is pursued concurrently. Through a formal model comparison, we showed that the multigoal model explains data better than a standard one-at-a-time subgoal model or a model that ignores subgoal structure altogether.

We have presented a theory of how one might represent and pursue multiple concurrent subgoals, and we have provided preliminary evidence that people actually do this. However, we don't have a theory of how they select which subgoals to pursue at any moment. Thus, in the context of the experiment, we treat $k$ as a latent variable to be inferred, not predicted. A more complete model would explain why people choose the $k$ they do, perhaps as a function of problem complexity or stakes. Such a theory could be constructed within the framework of resource-rational analysis \citep{Griffiths2014}, predicting that people choose a $k$ to optimize a tradeoff between the efficiency of the problem solution and the cost of representing and pursuing more complex multigoals. An important open question is how to quantify the cost of a multigoal, or even a standard subgoal.

Another major direction for future work is to remove the simplifying assumption of subgoal-ordering. This assumption allows us to reduce the problem of composing multigoals from a set of subgoals to the problem of selecting a single integer $k$, greatly simplifying model specification and inference. However many of the problems people are faced with do not have such an assumed ordering. To return to the initial motivating example, you do not know a priori whether you should go to a grocery store or library first. Unfortunately, choosing a multigoal from an unordered set of subgoals is a daunting task. With $n$ basic subgoals, there are $\binom{n}{k}$ possible multigoals of size $k$ that you could construct. But fortunately, as Colton demonstrates when he hands out roses at the end of each episode, people are entirely of capable of choosing $k$ out of $n$ options.

% In the general case with $n$ subgoals, there are $2^n$ possible multigoals. At a practical level, this poses a substantial challenge for infering which multigoal is guiding someone's behavior at any moment. But it also raises a theoretical question: How can people effectively choose multigoals when there are so many options? Addressing this question will be a challenging, but critical direction for future work.




\bibliographystyle{apacite}
\setlength{\bibleftmargin}{.125in}
\setlength{\bibindent}{-\bibleftmargin}
\renewcommand*{\bibfont}{\footnotesize}
\bibliography{references}


\end{document}
