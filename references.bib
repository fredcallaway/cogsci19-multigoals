% -----------------------------------------------------------------------
% File: CogSci_Template.bib
% -----------------------------------------------------------------------

% Modified : Eli M. Silk (esilk at pitt.edu)            05/24/2005
% Modified : David Noelle (dnoelle at ucmerced.edu)     11/19/2014

@article{ Griffiths2014,
author = {Griffiths, Thomas L and Lieder, Falk and Goodman, Noah D},
doi = {10.1111/tops.12142},
file = {:Users/fred/Dropbox/Articles/Mendeley/Griffiths, Lieder, Goodman - 2014 - Rational use of cognitive resources Levels of analysis between the computational and the algorith(2).pdf:pdf},
issn = {00367281},
journal = {Topics in Cognitive Science},
number = {2},
pages = {217--229},
title = {{Rational use of cognitive resources: Levels of analysis between the computational and the algorithmim}},
volume = {7},
year = {2014}
}


@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{Solway2014,
abstract = {Human behavior has long been recognized to display hierarchical structure: actions fit together into subtasks, which cohere into extended goal-directed activities. Arranging actions hierarchically has well established benefits, allowing behaviors to be represented efficiently by the brain, and allowing solutions to new tasks to be discovered easily. However, these payoffs depend on the particular way in which actions are organized into a hierarchy, the specific way in which tasks are carved up into subtasks. We provide a mathematical account for what makes some hierarchies better than others, an account that allows an optimal hierarchy to be identified for any set of tasks. We then present results from four behavioral experiments, suggesting that human learners spontaneously discover optimal action hierarchies.},
author = {Solway, Alec and Diuk, Carlos and C{\'{o}}rdova, Natalia and Yee, Debbie and Barto, Andrew G. and Niv, Yael and Botvinick, Matthew M.},
doi = {10.1371/journal.pcbi.1003779},
file = {:Users/fred/Dropbox/Articles/Mendeley/Solway et al. - 2014 - Optimal Behavioral Hierarchy.PDF:PDF},
isbn = {1553-7358 (Electronic)$\backslash$n1553-734X (Linking)},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {8},
pmid = {25122479},
title = {{Optimal Behavioral Hierarchy}},
volume = {10},
year = {2014}
}


@article{Cooper2006,
abstract = {Traditional accounts of sequential behavior assume that schemas and goals play a causal role in the control of behavior. In contrast, M. Botvinick and D. C. Plaut argued that, at least in routine behavior, schemas and goals are epiphenomenal. The authors evaluate the Botvinick and Plaut account by contrasting the simple recurrent network model of Botvinick and Plaut with their own more traditional hierarchically structured interactive activation model (R. P. Cooper {\&} T. Shallice, 2000). The authors present a range of arguments and additional simulations that demonstrate theoretical and empirical difficulties for both Botvinick and Plaut's model and their theoretical position. The authors conclude that explicit hierarchically organized and causally efficacious schema and goal representations are required to provide an adequate account of the flexibility of sequential behavior.},
author = {Cooper, Richard P. and Shallice, Tim},
doi = {10.1037/0033-295X.113.4.887},
file = {:Users/fred/Dropbox/Articles/Mendeley/Cooper, Shallice - 2006 - Hierarchical schemas and goals in the control of sequential behavior.pdf:pdf},
isbn = {0033-295X (Print)},
issn = {0033295X},
journal = {Psychological Review},
keywords = {Connectionist approach,Control of routine behavior,Localist versus distributed representations,Neuropsychological impairments of action,Sequential action,Simple recurrent networks},
number = {4},
pages = {887--916},
pmid = {17014307},
title = {{Hierarchical schemas and goals in the control of sequential behavior}},
volume = {113},
year = {2006}
}

@article{Donnarumma2016,
author = {Donnarumma, Francesco and Maisto, Domenico and Pezzulo, Giovanni},
doi = {10.1371/journal.pcbi.1004864},
file = {:Users/fred/Dropbox/Articles/Mendeley/Donnarumma, Maisto, Pezzulo - 2016 - Problem Solving as Probabilistic Inference with Subgoaling Explaining Human Successes and Pitfalls.PDF:PDF},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {4},
pages = {1--30},
pmid = {27074140},
title = {{Problem Solving as Probabilistic Inference with Subgoaling: Explaining Human Successes and Pitfalls in the Tower of Hanoi}},
volume = {12},
year = {2016}
}
@article{Dietterich2000,
archivePrefix = {arXiv},
arxivId = {cs/9905014},
author = {Dietterich, Thomas G.},
doi = {10.1613/jair.639},
eprint = {9905014},
file = {:Users/fred/Dropbox/Articles/Mendeley/Dietterich - 2000 - Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition.pdf:pdf},
isbn = {978-3-540-67839-7},
issn = {10769757},
journal = {Journal of Artificial Intelligence Research},
pages = {227--303},
primaryClass = {cs},
title = {{Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition}},
volume = {13},
year = {2000}
}


@article{Maisto2015,
author = {Maisto, D. and Donnarumma, F. and Pezzulo, G.},
doi = {10.1098/rsif.2014.1335},
file = {:Users/fred/Dropbox/Articles/Mendeley/Maisto, Donnarumma, Pezzulo - 2015 - Divide et impera subgoaling reduces the complexity of probabilistic inference and problem solving.pdf:pdf},
issn = {1742-5689},
journal = {Journal of The Royal Society Interface},
keywords = {Active inference,Hierarchies,Model-based reinforcement learning,Planning-as-inference,Problem solving,Subgoals},
month = {feb},
number = {104},
pages = {20141335--20141335},
title = {{Divide et impera: subgoaling reduces the complexity of probabilistic inference and problem solving}},
volume = {12},
year = {2015}
}


@article{VanDijk2011,
abstract = {Hierarchical structuring of behaviour is prevalent in natural and artificial agents and can be shown to be useful for learning and performing tasks. To progress systematic understanding of these benefits we study the effect of hierarchical architectures on the required information processing capability of an optimally acting agent. We show that an information-theoretical approach provides important insights into why factored and layered behaviour structures are beneficial.},
author = {{Van Dijk}, Sander G. and Polani, Daniel and Nehaniv, Chrystopher L.},
doi = {10.1007/978-3-642-21314-4_43},
file = {:Users/fred/Dropbox/Articles/Mendeley/Van Dijk, Polani, Nehaniv - 2011 - Hierarchical behaviours Getting the most bang for your bit.pdf:pdf},
isbn = {9783642213137},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 2},
pages = {342--349},
title = {{Hierarchical behaviours: Getting the most bang for your bit}},
volume = {5778 LNAI},
year = {2011}
}


@book{Anderson1990,
author = {Anderson, J R},
booktitle = {Hillsdale NJ Earlbaum},
doi = {10.4324/9780203771730},
eprint = {arXiv:1011.1669v3},
isbn = {0805804196},
issn = {0002-9556},
pages = {276},
pmid = {1026258},
title = {{The adaptive character of thought}},
volume = {104},
year = {1990}
}

@article{Daw2012,
author = {Daw, Nathaniel D and Gershman, Samuel J and Seymour, Ben and Dayan, Peter and Raymond, J},
doi = {10.1016/j.neuron.2011.02.027.Model-based},
file = {:Users/fred/Dropbox/Articles/Mendeley/Daw et al. - 2012 - Model-based influences on humans' choices and striatal prediction errors.pdf:pdf},
isbn = {078031901X},
issn = {2041-1723},
journal = {Neuron},
number = {6},
pages = {1204--1215},
title = {{Model-based influences on humans' choices and striatal prediction errors}},
volume = {69},
year = {2012}
}


@article{Simon2011,
  title={Neural correlates of forward planning in a spatial decision task in humans},
  author={Simon, Dylan Alexander and Daw, Nathaniel D},
  journal={Journal of Neuroscience},
  volume={31},
  number={14},
  pages={5526--5539},
  year={2011},
  publisher={Soc Neuroscience}
}

@book{Holding1985,
  title={The psychology of chess skill},
  author={Holding, Dennis Harry},
  year={1985},
  publisher={Lawrence Erlbaum}
}

@article{Keramati2011,
author = {Keramati, Mehdi and Dezfouli, Amir and Piray, Payam},
journal = {PLoS Comput Biol},
number = {5},
pages = {e1002055},
publisher = {Public Library of Science},
title = {{Speed/accuracy trade-off between the habitual and the goal-directed processes}},
volume = {7},
year = {2011}
}

@article{MacGregor2001,
  title={Information processing and insight: a process model of performance on the nine-dot and related problems.},
  author={MacGregor, James N and Ormerod, Thomas C and Chronicle, Edward P},
  journal={Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume={27},
  number={1},
  pages={176},
  year={2001},
  publisher={American Psychological Association}
}

@article{Krusche2018,
author = {Krusche, Moritz J F and Schulz, Eric and Guez, Arthur and Speekenbrink, Maarten},
doi = {10.1101/268938},
file = {:Users/fred/Dropbox/Articles/Mendeley/Krusche et al. - 2018 - Adaptive planning in human search.pdf:pdf},
journal = {bioRxiv},
keywords = {algorithms that are used,decision making,forag-,ing,monte carlo sampling,planning,planning as tree-search,reinforcement learning,tree search,tree-search algorithms are search},
pages = {0--5},
title = {{Adaptive planning in human search}},
year = {2018}
}

@book{anderson2013architecture,
  title={The architecture of cognition},
  author={Anderson, John R},
  year={2013},
  publisher={Psychology Press}
}

@article{laird1987soar,
  title={Soar: An architecture for general intelligence},
  author={Laird, John E and Newell, Allen and Rosenbloom, Paul S},
  journal={Artificial intelligence},
  volume={33},
  number={1},
  pages={1--64},
  year={1987},
  publisher={Elsevier}
}

@Book{NewellSimon1972,
  author =   {A. Newell and H. A. Simon},
  title =    {Human problem solving},
  publisher =    {Prentice-Hall},
  year =     1972,
  address =  {Englewood Cliffs, NJ}
}

@article{Keramati2016,
author = {Keramati, Mehdi and Smittenaar, Peter and Dolan, Raymond J and Dayan, Peter},
doi = {10.1073/pnas.1609094113},
title = {{Adaptive integration of habits into depth-limited planning defines a habitual-goal – directed spectrum}},
year = {2016}
}

@article{Campitelli2004,
author = {Campitelli, Guillermo and Gobet, Fernand R.},
issn = {1389-6911},
journal = {Journal of the International Computer Games Association},
number = {1995},
pages = {209--216},
title = {{Adaptive expert decision making: Skilled chessplayers search more and deeper}},
year = {2004}
}

@article{Huys2012,
author = {Huys, Quentin J M and Eshel, Neir and O'Nions, Elizabeth and Sheridan, Luke and Dayan, Peter and Roiser, Jonathan P},
journal = {PLoS Comput Biol},
keywords = {rl},
number = {3},
pages = {e1002410},
publisher = {Public Library of Science},
title = {{Bonsai trees in your head: how the Pavlovian system sculpts goal-directed choices by pruning decision trees}},
volume = {8},
year = {2012}
}

@article{Huys2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1408.1149},
author = {Huys, Quentin J M and Lally, N{\'{i}}all and Faulkner, Paul and Eshel, Neir and Seifritz, Erich and Gershman, Samuel J and Dayan, Peter and Roiser, Jonathan P},
doi = {10.1073/pnas.1414219112},
eprint = {arXiv:1408.1149},
isbn = {1091-6490 (Electronic)$\backslash$r0027-8424 (Linking)},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Humans,Intelligence,Planning Techniques,Stochastic Processes},
number = {10},
pages = {3098--103},
pmid = {25675480},
title = {{Interplay of approximate planning strategies.}},
volume = {112},
year = {2015}
}

@article{Kool2017,
author = {Kool, Wouter and Gershman, Samuel J. and Cushman, Fiery A.},
doi = {10.1177/0956797617708288},
file = {:Users/fred/Dropbox/Articles/Mendeley/Kool, Gershman, Cushman - 2017 - Cost-Benefit Arbitration Between Multiple Reinforcement-Learning Systems.pdf:pdf},
issn = {14679280},
journal = {Psychological Science},
keywords = {cognitive control,decision making,open data,open materials,reinforcement learning},
number = {9},
pages = {1321--1333},
pmid = {28731839},
title = {{Cost-Benefit Arbitration Between Multiple Reinforcement-Learning Systems}},
volume = {28},
year = {2017}
}

@article{Shallice1982,
author = {Timothy Shallice  and Donald Eric Broadbent  and Lawrence Weiskrantz },
title = {Specific impairments of planning},
journal = {Philosophical Transactions of the Royal Society of London. B, Biological Sciences},
volume = {298},
number = {1089},
pages = {199-209},
year = {1982},
doi = {10.1098/rstb.1982.0082},
}

@inproceedings{parr1998reinforcement,
  title={Reinforcement learning with hierarchies of machines},
  author={Parr, Ronald and Russell, Stuart J},
  booktitle={Advances in neural information processing systems},
  pages={1043--1049},
  year={1998}
}

@article{cobo2014abstraction,
title = "Abstraction from demonstration for efficient reinforcement learning in high-dimensional domains",
journal = "Artificial Intelligence",
volume = "216",
pages = "103 - 128",
year = "2014",
issn = "0004-3702",
author = "Luis C. Cobo and Kaushik Subramanian and Charles L. Isbell and Aaron D. Lanterman and Andrea L. Thomaz",
keywords = "Reinforcement learning, Learning from demonstration, Dimensionality reduction, Function approximation",
}

@inproceedings{bacon2017option,
  title={The Option-Critic Architecture.},
  author={Bacon, Pierre-Luc and Harb, Jean and Precup, Doina},
  booktitle={AAAI},
  pages={1726--1734},
  year={2017}
}

@article{sacerdoti1974planning,
  title={Planning in a hierarchy of abstraction spaces},
  author={Sacerdoti, Earl D},
  journal={Artificial intelligence},
  volume={5},
  number={2},
  pages={115--135},
  year={1974},
  publisher={Elsevier}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{botvinick2012hierarchical,
  title={Hierarchical reinforcement learning and decision making},
  author={Botvinick, Matthew Michael},
  journal={Current opinion in neurobiology},
  volume={22},
  number={6},
  pages={956--962},
  year={2012},
  publisher={Elsevier}
}

@inproceedings{kaelbling2010hierarchical,
  title={Hierarchical planning in the now},
  author={Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  booktitle={Workshops at the Twenty-Fourth AAAI Conference on Artificial Intelligence},
  year={2010}
}

@article{Kaller2011,
title = "Reviewing the impact of problem structure on planning: A software tool for analyzing tower tasks",
journal = "Behavioural Brain Research",
volume = "216",
number = "1",
pages = "1 - 8",
year = "2011",
issn = "0166-4328",
author = "Christoph P. Kaller and Benjamin Rahm and Lena Köstering and Josef M. Unterrainer",
keywords = "Tower of London, Tower of Hanoi, Planning, Problem structure",
}

@article{Simon1975,
title = "The functional equivalence of problem solving skills",
journal = "Cognitive Psychology",
volume = "7",
number = "2",
pages = "268 - 288",
year = "1975",
issn = "0010-0285",
doi = "https://doi.org/10.1016/0010-0285(75)90012-2",
author = "Herbert A Simon",
}

@article{Anderson2005,
  doi = {10.1162/0898929055002427},
  year  = {2005},
  month = {aug},
  publisher = {{MIT} Press - Journals},
  volume = {17},
  number = {8},
  pages = {1261--1274},
  author = {John R. Anderson and Mark V. Albert and Jon M. Fincham},
  title = {Tracing Problem Solving in Real Time: {fMRI} Analysis of the Subject-paced Tower of Hanoi},
  journal = {Journal of Cognitive Neuroscience}
}


@book{Sussman1975
 author = {Sussman, Gerald Jay},
 title = {A  Computer Model of Skill Acquisition},
 year = {1975},
 isbn = {044400159X},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
} 


% -----------------------------------------------------------------------
% Document End
% -----------------------------------------------------------------------
